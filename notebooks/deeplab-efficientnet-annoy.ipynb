{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 機械学習モデルによる画像特徴量抽出と近似最近傍探索を用いた類似画像検索 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "#### Basics  \n",
    "- [Similar Images Recommendations using FastAi and Annoy](https://towardsdatascience.com/similar-images-recommendations-using-fastai-and-annoy-16d6ceb3b809)\n",
    "- [Content Based Image Retrieval Using a Convolutional Denoising Autoencoder](https://medium.com/sicara/keras-tutorial-content-based-image-retrieval-convolutional-denoising-autoencoder-dc91450cc511)  \n",
    "\n",
    "#### Advanced\n",
    "- [Baseにおける類似画像検索](https://logmi.jp/tech/articles/322876)\n",
    "- [Yahooにおける類似画像検索](https://techblog.yahoo.co.jp/entry/2020081130014621/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview  \n",
    "- There are two main xxx, image feature extraction using pretrained deep-learning model and approximate nearest neighbors.\n",
    "- Use two pretrained deep-learning model, '[DeeplabV3](https://github.com/tensorflow/models/tree/master/research/deeplab)' and '[EfficientNet](https://arxiv.org/pdf/1905.11946.pdf)' to extract image feature.\n",
    "- Use python package by Spotify, named '[annoy](https://github.com/spotify/annoy)' for approximate nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from annoy import AnnoyIndex\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from libs.deeplabv3.model import Deeplabv3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Extract features (vector embeddings)  from images using pretrained ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define feature-extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.deeplab = Deeplabv3()\n",
    "        self.deeplab_person_region_index = 15\n",
    "        efficientnet_intermediate_layer_url = \"https://tfhub.dev/google/efficientnet/b0/feature-vector/1\"\n",
    "        self.efficientnet_input_shape = [224,224,3]\n",
    "        self.efficientnet_intermediate_layer = hub.KerasLayer(\n",
    "            efficientnet_intermediate_layer_url,\n",
    "            input_shape=self.efficientnet_input_shape)\n",
    "\n",
    "    def call(self, images, training=False):\n",
    "        deeplab_outputs = self.deeplab(images)\n",
    "        person_region_masks = tf.cast(tf.math.argmax(deeplab_outputs, -1) == self.deeplab_person_region_index, tf.float32)\n",
    "        masked_images = images * tf.stack([person_region_masks, person_region_masks, person_region_masks], axis=3)\n",
    "        resized_and_masked_images = tf.image.resize(masked_images, self.efficientnet_input_shape[:2])\n",
    "        self.image_features = self.efficientnet_intermediate_layer(resized_and_masked_images)\n",
    "        return self.image_features\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create input pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_path):\n",
    "    '''preprocess image to feed feature-extractor with appropriate input'''\n",
    "    target_image_shape=[512, 512]\n",
    "    num_channels = 3\n",
    "    raw_image = tf.io.read_file(image_path)\n",
    "    image_tensor = tf.image.decode_jpeg(raw_image, channels=num_channels)\n",
    "    resized_image_tensor = tf.image.resize(image_tensor, target_image_shape)\n",
    "    resized_and_normalized_image_tensor = resized_image_tensor/255.0\n",
    "    return resized_and_normalized_image_tensor\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "image_dir = \"/Volumes/Samsung_T5/19MH228/similar-image-retrieval/images/images_season_id_22\"\n",
    "image_path_list = glob.glob(image_dir + '/*.jpg')[::100]\n",
    "num_images = len(image_path_list)\n",
    "image_ids = np.array([int(os.path.splitext(os.path.basename(image_path))[0]) for image_path in image_path_list])\n",
    "batch_size = 1\n",
    "image_path_dataset = tf.data.Dataset.from_tensor_slices(image_path_list)\n",
    "image_dataset = image_path_dataset.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extract image features from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor()\n",
    "image_features = feature_extractor.predict(image_dataset, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save ids and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_save_dir = '../extracted-features'\n",
    "if not os.path.isdir(feature_save_dir):\n",
    "    os.mkdir(feature_save_dir)\n",
    "image_ids_save_path = '../extracted-features/image-ids.npy'\n",
    "image_features_save_path = '../extracted-features/image-features.npy'\n",
    "np.save(image_ids_save_path, image_ids)\n",
    "np.save(image_features_save_path, image_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Build index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build annoy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids_save_path = '../extracted-features/image-ids.npy'\n",
    "image_features_save_path = '../extracted-features/image-features.npy'\n",
    "image_ids = np.load(image_ids_save_path)\n",
    "image_features = np.load(image_features_save_path)\n",
    "image_vector_dims = image_features.shape[1]\n",
    "num_trees = 50\n",
    "metric = 'euclidean'\n",
    "annoy_model = AnnoyIndex(image_vector_dims, metric)\n",
    "for image_id, image_vector in tqdm(zip(image_ids, image_features)):\n",
    "    annoy_model.add_item(image_id, image_vector)\n",
    "annoy_model.build(num_trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save index model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_dir = '../models'\n",
    "if not os.path.isdir(model_save_dir):\n",
    "    os.mkdir(model_save_dir)\n",
    "annoy_model_save_path = \"../models/{}-{}-{}.ann\".format(image_vector_dims, metric, num_trees)\n",
    "annoy_model.save(annoy_model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check avairable annoy models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_dir = '../models'\n",
    "print('Avairable annoy models -> {}'.format(glob.glob(model_save_dir+'/*.ann')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test similar image retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "annoy_model_path = '../models/1280-euclidean-50.ann'\n",
    "metric = os.path.basename(annoy_model_path).split('-')[1]\n",
    "num_feature_dims = int(os.path.basename(annoy_model_path).split('-')[0])\n",
    "annoy_model = AnnoyIndex(num_feature_dims, metric)\n",
    "annoy_model.load(annoy_model_path)\n",
    "ext = \".jpg\"\n",
    "image_id_and_arrays = []\n",
    "for query_image_path in tqdm(glob.glob(image_dir + \"/*\"+ext)[::900]):\n",
    "    num_neighbors = 5\n",
    "    query_image_id = int(os.path.splitext(os.path.basename(query_image_path))[0])\n",
    "    nearest_neigbor_ids, distances = annoy_model.get_nns_by_item(\n",
    "        query_image_id, \n",
    "        num_neighbors, \n",
    "        search_k=-1,\n",
    "        include_distances=True\n",
    "    )\n",
    "    query_image = Image.open(query_image_path)\n",
    "    query_image_array = np.array(query_image)\n",
    "    fig = plt.figure(figsize=(40, 20))\n",
    "    ax = fig.add_subplot(1, num_neighbors+1, 1)\n",
    "    ax.imshow(query_image_array)\n",
    "    ax.set_title('query\\nimage_id -> {}\\n'.format(query_image_id))\n",
    "    ax.axis(\"off\")\n",
    "    for i, (neigbor_image_id, distance) in enumerate(zip(nearest_neigbor_ids, distances)):\n",
    "        image_file = os.path.join(image_dir, str(neigbor_image_id)+ext)\n",
    "        image = Image.open(image_file)\n",
    "        image_array = np.array(image)\n",
    "        ax = fig.add_subplot(1, num_neighbors+1, i+2)\n",
    "        ax.imshow(image_array)\n",
    "        rank_statement = \"1st\" if i == 0 else \"2nd\" if i == 1 else \"3rd\" if i == 2 else \"{}th\".format(i+1)\n",
    "        ax.set_title('{}\\nimage_id -> {}\\ndistance -> {}'.format(rank_statement, neigbor_image_id, distance))\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
